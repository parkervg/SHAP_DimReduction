{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon-review-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6o1qlJREcEF",
        "outputId": "7e4f7d79-b724-4d46-e2d5-d1b75dc71d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"drive/My Drive/shap-dim-reduction/shap-dim-reduction\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/shap-dim-reduction/shap-dim-reduction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq80fJN9IoCN",
        "outputId": "13b91074-a7bb-4b9b-ff88-75a24a3a44e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "  ! git config --global user.email \"parkervg5@gmail.com\"\n",
        "  ! git config --global user.name \"parkervg\"\n",
        "  ! git pull\n",
        "except:\n",
        "  ! git stash \n",
        "  ! git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746QWXAJII4d"
      },
      "source": [
        "try:\n",
        "  import shap \n",
        "except:\n",
        "  !pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWKX6_NgK0WB",
        "outputId": "d7bcda06-736d-4c7b-8742-6eefdff14f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUMh99GaEHrp",
        "outputId": "6b67f207-015d-4938-e046-5ed93ed6c022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import bz2\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lib.ProcessEmbeddings import WordEmbeddings\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 01:41:47 INFO     'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLcKkbXZu5F6"
      },
      "source": [
        "DIMS = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHfo1D_mmrha"
      },
      "source": [
        "##Definition of Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56ePauJ6ltUO"
      },
      "source": [
        "def get_sent_vectors(sents, word_vectors, wvec_dim):\n",
        "  \"\"\"\n",
        "  Averages over all word vectors in a sentence.\n",
        "  \"\"\"\n",
        "  embeddings = []\n",
        "  for sent in sents:\n",
        "      sentvec = []\n",
        "      for word in word_tokenize(sent):\n",
        "        try:\n",
        "            sentvec.append(word_vectors[word.lower()])\n",
        "        except:\n",
        "            pass\n",
        "      if not sentvec:\n",
        "          vec = np.zeros(wvec_dim)\n",
        "          sentvec.append(vec)\n",
        "      sentvec = np.mean(sentvec, 0)\n",
        "      embeddings.append(sentvec)\n",
        "  embeddings = np.vstack(embeddings)\n",
        "  return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pNEeGHLFbIz"
      },
      "source": [
        "def standard_glove():\n",
        "  WE = WordEmbeddings(vector_file=\"embeds/glove.6B.300d.txt\")\n",
        "  word_vectors = WE.get_vector_dict()\n",
        "  wvec_dim = WE.embeds.shape[1]\n",
        "  return get_sent_vectors(train_text, word_vectors, wvec_dim), get_sent_vectors(test_text, word_vectors, wvec_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsX1GpJbcLQE"
      },
      "source": [
        "def algo_glove(output_dims):\n",
        "  \"\"\"\n",
        "  Following the \"Algo-N\" process described in https://www.aclweb.org/anthology/W19-4328/\n",
        "  \"\"\"\n",
        "  WE = WordEmbeddings(vector_file=\"embeds/glove.6B.300d.txt\")\n",
        "  # PPE\n",
        "  WE.subract_mean()\n",
        "  WE.pca_fit()\n",
        "  WE.remove_top_components(k=7)\n",
        "\n",
        "  # PCA dim reduction\n",
        "  WE.subract_mean()\n",
        "  WE.pca_fit_transform(output_dims=output_dims)\n",
        "\n",
        "  # PPE\n",
        "  WE.subract_mean()\n",
        "  WE.pca_fit()\n",
        "  WE.remove_top_components(k=7)\n",
        "  \n",
        "  word_vectors = WE.get_vector_dict()\n",
        "  wvec_dim = WE.embeds.shape[1]\n",
        "  return get_sent_vectors(train_text, word_vectors, wvec_dim), get_sent_vectors(test_text, word_vectors, wvec_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1kXnhsjLmIV"
      },
      "source": [
        "def shap_glove(task, output_dims):\n",
        "  WE = WordEmbeddings(vector_file=\"embeds/glove.6B.300d.txt\")\n",
        "  dims = WE.shap_dim_reduction(task=task, k=output_dims)\n",
        "  word_vectors = WE.get_vector_dict()\n",
        "  wvec_dim = WE.embeds.shape[1]\n",
        "  return get_sent_vectors(train_text, word_vectors, wvec_dim), get_sent_vectors(test_text, word_vectors, wvec_dim), dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3j6kfAzQssR"
      },
      "source": [
        "def rand_dims_glove(k, avoid_dims=[]):\n",
        "  WE = WordEmbeddings(vector_file=\"embeds/glove.6B.300d.txt\")\n",
        "  dims = WE.rand_dim_reduction(k=k, avoid_dims=avoid_dims)\n",
        "  word_vectors = WE.get_vector_dict()\n",
        "  wvec_dim = WE.embeds.shape[1]\n",
        "  return get_sent_vectors(train_text, word_vectors, wvec_dim), get_sent_vectors(test_text, word_vectors, wvec_dim), dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki3d9s-oEPaQ"
      },
      "source": [
        "def labels_text(x):\n",
        "  label=[]\n",
        "  text=[]\n",
        "  for line in bz2.BZ2File(x):\n",
        "    decode = line.decode(\"utf-8\")\n",
        "    label.append(int(decode[9]) - 1)\n",
        "    text.append(decode[10:].strip())\n",
        "  return np.array(label),text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOHxoceFPC6M"
      },
      "source": [
        "##Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV-dg63cPA67"
      },
      "source": [
        "train_label, train_text = labels_text('data/amazon-reviews/train.ft.txt.bz2')\n",
        "test_label, test_text = labels_text('data/amazon-reviews/test.ft.txt.bz2')\n",
        "\n",
        "# We're only using a subset of the dataset, so we shuffle it \n",
        "train_text, train_label = shuffle(train_text, train_label)\n",
        "test_text, test_label = shuffle(test_text, test_label)\n",
        "\n",
        "train_text = train_text[:10000]\n",
        "train_label = train_label[:10000]\n",
        "test_text = test_text[:5000]\n",
        "test_label = test_label[:5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ngMrBEm8FH"
      },
      "source": [
        "##Loading Processed Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAygqewVHTka",
        "outputId": "9a9a9056-e604-4660-f4dd-cb41027f69a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xtrain_glove, Xtest_glove = standard_glove()\n",
        "\n",
        "Xtrain_algo, Xtest_algo = algo_glove(output_dims=DIMS)\n",
        "\n",
        "Xtrain_shap_cr, Xtest_shap_cr, cr_dims = shap_glove(task=\"CR\", output_dims=DIMS)\n",
        "\n",
        "Xtrain_shap_mpqa, Xtest_shap_mpqa, mpqa_dims = shap_glove(task=\"MPQA\", output_dims=DIMS)\n",
        "\n",
        "Xtrain_shap_trec, Xtest_shap_trec, trec_dims = shap_glove(task=\"TREC\", output_dims=DIMS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 01:43:30 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:44:00 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:45:06 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:45:23 INFO     \u001b[37mFound 5282 words with word vectors, out of             5677 words\u001b[0m\n",
            "2020-11-10 01:45:23 INFO     Generating sentence embeddings\n",
            "2020-11-10 01:45:24 INFO     Generated sentence embeddings\n",
            "2020-11-10 01:45:24 INFO     Training sklearn-LogReg with (inner) 5-fold cross-validation\n",
            "2020-11-10 01:45:26 INFO     Best param found at split 1: l2reg = 2                 with score 78.01\n",
            "2020-11-10 01:45:28 INFO     Best param found at split 2: l2reg = 2                 with score 77.45\n",
            "2020-11-10 01:45:31 INFO     Best param found at split 3: l2reg = 4                 with score 78.71\n",
            "2020-11-10 01:45:33 INFO     Best param found at split 4: l2reg = 4                 with score 78.34\n",
            "2020-11-10 01:45:35 INFO     Best param found at split 5: l2reg = 1                 with score 77.65\n",
            "2020-11-10 01:45:36 INFO     \u001b[36mOriginal accuracy on task CR: 78.36\u001b[0m\n",
            "2020-11-10 01:45:36 INFO     \u001b[37mClassifier has 2 classes\u001b[0m\n",
            "2020-11-10 01:45:36 INFO     \u001b[36mNew shape of embeds is (400000, 50)\u001b[0m\n",
            "2020-11-10 01:45:46 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:46:04 INFO     \u001b[37mFound 6195 words with word vectors, out of             6241 words\u001b[0m\n",
            "2020-11-10 01:46:04 INFO     Generating sentence embeddings\n",
            "2020-11-10 01:46:04 INFO     Generated sentence embeddings\n",
            "2020-11-10 01:46:04 INFO     Training sklearn-LogReg with (inner) 5-fold cross-validation\n",
            "2020-11-10 01:46:09 INFO     Best param found at split 1: l2reg = 0.25                 with score 87.06\n",
            "2020-11-10 01:46:15 INFO     Best param found at split 2: l2reg = 0.25                 with score 86.39\n",
            "2020-11-10 01:46:20 INFO     Best param found at split 3: l2reg = 1                 with score 86.94\n",
            "2020-11-10 01:46:25 INFO     Best param found at split 4: l2reg = 8                 with score 86.89\n",
            "2020-11-10 01:46:31 INFO     Best param found at split 5: l2reg = 0.25                 with score 86.91\n",
            "2020-11-10 01:46:31 INFO     \u001b[36mOriginal accuracy on task MPQA: 87.11\u001b[0m\n",
            "2020-11-10 01:46:31 INFO     \u001b[37mClassifier has 2 classes\u001b[0m\n",
            "2020-11-10 01:46:31 INFO     \u001b[36mNew shape of embeds is (400000, 50)\u001b[0m\n",
            "2020-11-10 01:46:42 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:46:59 INFO     ***** Transfer task : TREC *****\n",
            "\n",
            "\n",
            "2020-11-10 01:46:59 INFO     \u001b[37mFound 5867 words with word vectors, out of             9779 words\u001b[0m\n",
            "2020-11-10 01:47:00 INFO     Computed train embeddings\n",
            "2020-11-10 01:47:00 INFO     Computed test embeddings\n",
            "2020-11-10 01:47:00 INFO     Training sklearn-LogReg with 5-fold cross-validation\n",
            "2020-11-10 01:47:17 INFO     [('reg:0.5', 63.52), ('reg:1', 63.15), ('reg:2', 62.82), ('reg:4', 62.8), ('reg:8', 62.56), ('reg:16', 62.45), ('reg:32', 62.38)]\n",
            "2020-11-10 01:47:17 INFO     Cross-validation : best param found is reg = 0.5             with score 63.52\n",
            "2020-11-10 01:47:17 INFO     Evaluating...\n",
            "2020-11-10 01:47:17 INFO     \u001b[36mOriginal accuracy on task TREC: 67.0\u001b[0m\n",
            "2020-11-10 01:47:18 INFO     \u001b[37mClassifier has 6 classes\u001b[0m\n",
            "2020-11-10 01:47:18 INFO     \u001b[36mNew shape of embeds is (400000, 50)\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jjA5IKNZpwN"
      },
      "source": [
        "Full 300 dimension Glove accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AwzCMtFHf9f",
        "outputId": "95ceb8f3-2d75-4be0-d7e8-a1e966c67ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_glove, train_label)\n",
        "print(round(clf.score(Xtest_glove, test_label)* 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-2l8fu7Pbpj",
        "outputId": "9b5de831-9976-4474-d817-0b3e9cfe1998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting SHAP to the amazon-review dataset\n",
        "\n",
        "WE = WordEmbeddings(vector_file=\"embeds/glove.6B.300d.txt\")\n",
        "glove_dims = WE.top_shap_dimensions(clf, Xtrain_glove, k=DIMS)\n",
        "Xtrain_glove_reduced = np.take(Xtrain_glove, indices=glove_dims, axis=1)\n",
        "Xtest_glove_reduced = np.take(Xtest_glove, indices=glove_dims, axis=1)\n",
        "\n",
        "# Random sample dimensions as baseline\n",
        "# With 300 dimensions and k = 150, basically just all 150 dimensions not in glove_dims\n",
        "Xtrain_rand, Xtest_rand, rand_dims = rand_dims_glove(avoid_dims=glove_dims, k=DIMS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 01:47:29 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:47:46 INFO     \u001b[37mClassifier has 2 classes\u001b[0m\n",
            "2020-11-10 01:47:46 INFO     \u001b[36mLoading vectors at embeds/glove.6B.300d.txt...\u001b[0m\n",
            "2020-11-10 01:48:04 INFO     \u001b[36mRandomly selected dimension indices [101, 3, 197, 282, 234, 122, 82, 223, 115, 233, 7, 161, 159, 56, 172, 88, 279, 136, 195, 95, 27, 186, 121, 91, 176, 69, 89, 42, 235, 296, 138, 284, 65, 116, 35, 255, 263, 143, 231, 294, 155, 157, 0, 5, 180, 1, 33, 57, 54, 241]\u001b[0m\n",
            "2020-11-10 01:48:04 INFO     \u001b[36mNew shape of embeds is (400000, 50)\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAkb5_9RQ9cp"
      },
      "source": [
        "SHAP amazon-review reduced Glove accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOzqC3UjRB8g",
        "outputId": "cdff0b7b-192c-4109-808d-3fce66bff92f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_glove_reduced, train_label)\n",
        "print(round(clf.score(Xtest_glove_reduced, test_label) * 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oIgsNFHc6NJ"
      },
      "source": [
        "Algo-N reduced Glove accuracy: 50 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWiwku8rc9P7",
        "outputId": "f8642a3d-d2b9-4242-a145-d5f33441090b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_algo, train_label)\n",
        "print(round(clf.score(Xtest_algo, test_label) * 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhNRpTvCZsrR"
      },
      "source": [
        "SHAP reduced accuracy on CR\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdJWA879LWKz",
        "outputId": "1c1ed23d-e945-4db2-9547-398cf75d0416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_shap_cr, train_label)\n",
        "print(round(clf.score(Xtest_shap_cr, test_label) * 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4fNW9JvM27z"
      },
      "source": [
        "SHAP reduced on MPQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAtOuzmJM5Na",
        "outputId": "3640b1f4-0865-4644-8418-3deb47941a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_shap_mpqa, train_label)\n",
        "print(round(clf.score(Xtest_shap_mpqa, test_label) * 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGhFNq9wf8NS"
      },
      "source": [
        "SHAP reduced on TREC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EkADnGqigo4",
        "outputId": "59803e55-fc5a-408f-b383-fa65a9ab75e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_shap_trec, train_label)\n",
        "print(round(clf.score(Xtest_shap_trec, test_label) * 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKRmzDoBZvay"
      },
      "source": [
        "Randomly reduced 50 dimension accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0wZIm8qTE-O",
        "outputId": "69b23437-c009-4c57-f695-c123a2164a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain_rand, train_label)\n",
        "print(round(clf.score(Xtest_rand, test_label) * 100, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c81EEDvmRkua",
        "outputId": "614fb4f3-c73c-4ade-a6bb-ba3c4c6ba3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def intersect(a, b):\n",
        "  return len(list(set(a) & set(b)))\n",
        "print(f\"Intersecting dims between CR and amazon-review: {intersect(glove_dims, cr_dims)}\")\n",
        "print()\n",
        "print(f\"Intersecting dims between MR and amazon-review: {intersect(glove_dims, mpqa_dims)}\")\n",
        "print()\n",
        "print(f\"Intersecting dims between TREC and amazon-review: {intersect(glove_dims, trec_dims)}\")\n",
        "print()\n",
        "print(f\"Intersecting dims between random dims and amazon-review: {intersect(glove_dims, rand_dims)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intersecting dims between CR and amazon-review: 18\n",
            "\n",
            "Intersecting dims between MR and amazon-review: 13\n",
            "\n",
            "Intersecting dims between TREC and amazon-review: 11\n",
            "\n",
            "Intersecting dims between random dims and amazon-review: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
